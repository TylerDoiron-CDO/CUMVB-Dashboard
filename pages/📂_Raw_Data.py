import streamlit as st
import pandas as pd
import os
from functions import (
    Athlete_Data_Load,
    Overall_Data_Load,
    Rotation_Data_Load,
    Match_Data_Load
)

st.set_page_config(page_title="ğŸ“‚ Raw Data Viewer", layout="wide")

# Summary intro for the full page
st.markdown("""
## ğŸ“‚ Raw Data Viewer
This page provides full access to the underlying match, rotation, overall, and athlete data used throughout the analytics dashboards.
It is intended for exploratory analysis, enabling filters, downloads, and quick reviews of data trends. Use the navigation below to jump to specific sections.
""")

# Horizontal navigation buttons
nav1, nav2, nav3, nav4, nav5 = st.columns(5)
with nav1:
    if st.button("ğŸ“˜ Match Data"):
        st.experimental_set_query_params(section="match")
with nav2:
    if st.button("ğŸ“Š Overall Data"):
        st.experimental_set_query_params(section="overall")
with nav3:
    if st.button("ğŸ”„ Rotation Data"):
        st.experimental_set_query_params(section="rotation")
with nav4:
    if st.button("ğŸ Athlete Data"):
        st.experimental_set_query_params(section="athlete")
with nav5:
    if st.button("ğŸ“Š Setter Dist. Data"):
        st.experimental_set_query_params(section="setter")

st.markdown("---")

force_refresh_match = st.session_state.get("reset_cache_match", False)

with st.spinner("ğŸ”„ Loading Match Data..."):
    match_df = Match_Data_Load.load_preprocessed_match_data(force_rebuild=force_refresh_match)

if match_df.empty:
    st.title("ğŸ“˜ Match Data â€” No Records Found")
    st.warning("âš ï¸ No match data found or processed.")
else:
    # Normalize team names
    match_df["Home"] = match_df["Home"].replace({"CU": "Crandall", "Holland College": "Holland"})
    match_df["Away"] = match_df["Away"].replace({"CU": "Crandall", "Holland College": "Holland"})
    match_df["Team"] = match_df["Team"].replace({"CU": "Crandall", "Holland College": "Holland"})

    # Filter for Crandall team only for summary
    crandall_matches = match_df[match_df["Team"] == "Crandall"]
    season_summary = crandall_matches.groupby("Season").size().reset_index(name="Records")

    latest_date = pd.to_datetime(match_df["Date"], errors='coerce').dropna().max()
    latest_date_str = latest_date.date() if pd.notnull(latest_date) else "Unknown"

    # Title with latest date only
    st.title(f"ğŸ“˜ Match Data â€” Latest Match: {latest_date_str}")

    # Summary section (inline single line)
    summary_line = " | ".join([f"{row['Season']}: {row['Records']} records" for _, row in season_summary.iterrows()])
    st.markdown(f"### ğŸ“Š Summary by Season â€” {summary_line}")

    # Explanation
    st.caption("This dataset includes all point-by-point match data for every set played in the tracked seasons. Summary counts reflect only matches played by Crandall.")

    # Filters
    col1, col2, col3, col4 = st.columns(4)
    seasons = sorted(match_df["Season"].dropna().unique())
    homes = sorted(match_df["Home"].dropna().unique())
    aways = sorted(match_df["Away"].dropna().unique())
    teams = sorted(match_df["Team"].dropna().unique())

    f_season = col1.multiselect("Season", options=seasons)
    f_home = col2.multiselect("Home", options=homes)
    f_away = col3.multiselect("Away", options=aways)
    f_team = col4.multiselect("Team", options=teams)

    filtered_match = match_df.copy()
    if f_season:
        filtered_match = filtered_match[filtered_match["Season"].isin(f_season)]
    if f_home:
        filtered_match = filtered_match[filtered_match["Home"].isin(f_home)]
    if f_away:
        filtered_match = filtered_match[filtered_match["Away"].isin(f_away)]
    if f_team:
        filtered_match = filtered_match[filtered_match["Team"].isin(f_team)]

    st.success(f"âœ… {filtered_match.shape[0]} match records shown")
    st.dataframe(filtered_match)

    col1, col2 = st.columns([3, 1])
    with col1:
        st.download_button("ğŸ’¾ Download Match CSV", filtered_match.to_csv(index=False).encode("utf-8"), "match_data.csv", "text/csv")
    with col2:
        if st.button("ğŸ” Reset Match Cache"):
            if os.path.exists(Match_Data_Load.CACHE_FILE):
                os.remove(Match_Data_Load.CACHE_FILE)
                st.session_state["reset_cache_match"] = True
                st.rerun()
            else:
                st.info("â„¹ï¸ No match cache found.")
        st.caption("âš ï¸ Only use if source match data changed.")

st.markdown("---")

# -------------------------------
# Section 2: Overall Data
# -------------------------------
st.header("ğŸ“Š Overall Data")

force_refresh_overall = st.session_state.get("reset_cache_overall", False)

with st.spinner("ğŸ”„ Loading Overall Data..."):
    overall_df = Overall_Data_Load.load_preprocessed_overall_data(force_rebuild=force_refresh_overall)

if overall_df.empty:
    st.warning("âš ï¸ No overall data found or processed.")
else:
    # Normalize team names
    overall_df["Home"] = overall_df["Home"].replace({"CU": "Crandall", "Holland College": "Holland"})
    overall_df["Away"] = overall_df["Away"].replace({"CU": "Crandall", "Holland College": "Holland"})
    overall_df["Team"] = overall_df["Team"].replace({"CU": "Crandall", "Holland College": "Holland"})

    if "Matches" in overall_df.columns:
        overall_df = overall_df[overall_df["Matches"].astype(str).str.strip().str.isnumeric()]
        overall_df = overall_df[overall_df["Matches"].astype(int).between(0, 5)]

    col1, col2, col3, col4 = st.columns(4)
    seasons = sorted(overall_df["Season"].dropna().unique())
    homes = sorted(overall_df["Home"].dropna().unique())
    aways = sorted(overall_df["Away"].dropna().unique())
    teams = sorted(overall_df["Team"].dropna().unique())
    f_season = col1.multiselect("Overall Season", options=seasons, key="overall_season")
    f_home = col2.multiselect("Overall Home", options=homes, key="overall_home")
    f_away = col3.multiselect("Overall Away", options=aways, key="overall_away")
    f_team = col4.multiselect("Overall Team", options=teams, key="overall_team")

    filtered_overall = overall_df.copy()
    if f_season:
        filtered_overall = filtered_overall[filtered_overall["Season"].isin(f_season)]
    if f_home:
        filtered_overall = filtered_overall[filtered_overall["Home"].isin(f_home)]
    if f_away:
        filtered_overall = filtered_overall[filtered_overall["Away"].isin(f_away)]
    if f_team:
        filtered_overall = filtered_overall[filtered_overall["Team"].isin(f_team)]

    st.success(f"âœ… {filtered_overall.shape[0]} overall records shown")
    st.dataframe(filtered_overall)

    col1, col2 = st.columns([3, 1])
    with col1:
        st.download_button("ğŸ’¾ Download Overall CSV", filtered_overall.to_csv(index=False).encode("utf-8"), "overall_data.csv", "text/csv")
    with col2:
        if st.button("ğŸ” Reset Overall Cache"):
            if os.path.exists(Overall_Data_Load.CACHE_FILE):
                os.remove(Overall_Data_Load.CACHE_FILE)
                st.session_state["reset_cache_overall"] = True
                st.rerun()
            else:
                st.info("â„¹ï¸ No overall cache found.")
        st.caption("âš ï¸ Only use if source overall data changed.")

st.markdown("---")

# -------------------------------
# Section 3: Rotation Data
# -------------------------------
st.header("ğŸ”„ Rotation Data")

force_refresh_rotation = st.session_state.get("reset_cache_rotation", False)

with st.spinner("ğŸ”„ Loading Rotation Data..."):
    rotation_df = Rotation_Data_Load.load_preprocessed_rotation_data(force_rebuild=force_refresh_rotation)

if rotation_df.empty:
    st.warning("âš ï¸ No rotation data found or processed.")
else:
    # Normalize team names
    rotation_df["Home"] = rotation_df["Home"].replace({"CU": "Crandall", "Holland College": "Holland"})
    rotation_df["Away"] = rotation_df["Away"].replace({"CU": "Crandall", "Holland College": "Holland"})
    rotation_df["Team"] = rotation_df["Team"].replace({"CU": "Crandall", "Holland College": "Holland"})

    if "Rotation" in rotation_df.columns:
        rotation_df["Rotation_str"] = rotation_df["Rotation"].astype(str).str.strip()
        rotation_df = rotation_df[
            rotation_df["Rotation_str"].isin(["0", "1", "2", "3", "4", "5", "Unknown", "unknown", "nan"])
        ]
        rotation_df.drop(columns=["Rotation_str"], inplace=True, errors="ignore")

    s1, s2, s3, s4 = st.columns(4)
    seasons = sorted(rotation_df["Season"].dropna().unique())
    homes = sorted(rotation_df["Home"].dropna().unique())
    aways = sorted(rotation_df["Away"].dropna().unique())
    teams = sorted(rotation_df["Team"].dropna().unique())
    f_season = s1.multiselect("Rotation Season", options=seasons, key="rotation_season")
    f_home = s2.multiselect("Rotation Home", options=homes, key="rotation_home")
    f_away = s3.multiselect("Rotation Away", options=aways, key="rotation_away")
    f_team = s4.multiselect("Rotation Team", options=teams, key="rotation_team")

    filtered_rotation = rotation_df.copy()
    if f_season:
        filtered_rotation = filtered_rotation[filtered_rotation["Season"].isin(f_season)]
    if f_home:
        filtered_rotation = filtered_rotation[filtered_rotation["Home"].isin(f_home)]
    if f_away:
        filtered_rotation = filtered_rotation[filtered_rotation["Away"].isin(f_away)]
    if f_team:
        filtered_rotation = filtered_rotation[filtered_rotation["Team"].isin(f_team)]

    st.success(f"âœ… {filtered_rotation.shape[0]} rotation records shown")
    st.dataframe(filtered_rotation)

    c1, c2 = st.columns([3, 1])
    with c1:
        st.download_button("ğŸ’¾ Download Rotation CSV", filtered_rotation.to_csv(index=False).encode("utf-8"), "rotation_data.csv", "text/csv")
    with c2:
        if st.button("ğŸ” Reset Rotation Cache"):
            if os.path.exists(Rotation_Data_Load.CACHE_FILE):
                os.remove(Rotation_Data_Load.CACHE_FILE)
                st.session_state["reset_cache_rotation"] = True
                st.rerun()
            else:
                st.info("â„¹ï¸ No rotation cache found.")
        st.caption("âš ï¸ Only use if source rotation data changed.")

st.markdown("---")

# -------------------------------
# Section 4: Athlete Data
# -------------------------------
st.header("ğŸ Athlete Data")

force_refresh_athlete = st.session_state.get("reset_cache_athlete", False)
with st.spinner("ğŸ”„ Loading Athlete Data..."):
    athlete_df = Athlete_Data_Load.load_preprocessed_athlete_data(force_rebuild=force_refresh_athlete)

if athlete_df.empty:
    st.warning("âš ï¸ No athlete data found or processed.")
else:
    # Normalize team names
    athlete_df["Home"] = athlete_df["Home"].replace({"CU": "Crandall", "Holland College": "Holland"})
    athlete_df["Away"] = athlete_df["Away"].replace({"CU": "Crandall", "Holland College": "Holland"})
    athlete_df["Team"] = athlete_df["Team"].replace({"CU": "Crandall", "Holland College": "Holland"})

    # Create combined index column without decimal padding
    if "#" in athlete_df.columns and "Athlete" in athlete_df.columns:
        athlete_df.insert(0, "# - Athlete", athlete_df["#"].apply(lambda x: str(int(float(x))) if pd.notnull(x) and str(x).replace('.', '', 1).isdigit() else str(x)) + " - " + athlete_df["Athlete"].astype(str).str.strip())

    col1, col2, col3, col4, col5 = st.columns(5)
    seasons = sorted(athlete_df["Season"].dropna().unique())
    teams = sorted(athlete_df["Team"].dropna().unique()) if "Team" in athlete_df.columns else []
    homes = sorted(athlete_df["Home"].dropna().unique())
    aways = sorted(athlete_df["Away"].dropna().unique())
    names = sorted(athlete_df["Athlete"].dropna().unique()) if "Athlete" in athlete_df.columns else []
    s_seasons = col1.multiselect("Athlete Season", options=seasons)
    s_teams = col2.multiselect("Athlete Team", options=teams)
    s_home = col3.multiselect("Athlete Home", options=homes)
    s_away = col4.multiselect("Athlete Away", options=aways)
    s_name = col5.text_input("Search Athlete")

    filtered_athlete = athlete_df.copy()
    if s_seasons:
        filtered_athlete = filtered_athlete[filtered_athlete["Season"].isin(s_seasons)]
    if s_teams:
        filtered_athlete = filtered_athlete[filtered_athlete["Team"].isin(s_teams)]
    if s_home:
        filtered_athlete = filtered_athlete[filtered_athlete["Home"].isin(s_home)]
    if s_away:
        filtered_athlete = filtered_athlete[filtered_athlete["Away"].isin(s_away)]
    if s_name and "Athlete" in filtered_athlete.columns:
        filtered_athlete = filtered_athlete[filtered_athlete["Athlete"].str.contains(s_name, case=False, na=False)]

    st.success(f"âœ… {filtered_athlete.shape[0]} athlete records shown")
    latest_athlete_date = pd.to_datetime(filtered_athlete["Date"], errors='coerce').dropna().max()
    if pd.notnull(latest_athlete_date):
        st.markdown(f"**ğŸ—“ï¸ Athlete data current as of:** {latest_athlete_date.date()}")

    st.dataframe(filtered_athlete)

    col1, col2 = st.columns([3, 1])
    with col1:
        st.download_button("ğŸ’¾ Download Athlete CSV", filtered_athlete.to_csv(index=False).encode("utf-8"), "athlete_data.csv", "text/csv")
    with col2:
        if st.button("ğŸ” Reset Athlete Cache"):
            if os.path.exists(Athlete_Data_Load.CACHE_FILE):
                os.remove(Athlete_Data_Load.CACHE_FILE)
                st.session_state["reset_cache_athlete"] = True
                st.rerun()
            else:
                st.info("â„¹ï¸ No athlete cache found.")
        st.caption("âš ï¸ Only use if source athlete data changed.")

st.markdown("---")

# -------------------------------
# Section 5: Setter Distribution Data
# -------------------------------
st.header("ğŸ“Š Setter Distribution Data")

setter_file = "data/Setter Distribution Data.csv"
match_file = "data/Match Data by Set.csv"

if os.path.exists(setter_file):
    try:
        setter_df = pd.read_csv(setter_file)

        # Rename TEAM to Team for consistency
        setter_df.rename(columns={"TEAM": "Team"}, inplace=True)

        # Load match data
        if os.path.exists(match_file):
            match_df = pd.read_csv(match_file)
            match_df["Date"] = pd.to_datetime(match_df["Date"], errors='coerce')
            setter_df["Date"] = pd.to_datetime(setter_df["Date"], errors='coerce')

            # Map Home and Away based on matching date and team logic
            home_list, away_list = [], []
            for _, row in setter_df.iterrows():
                match_subset = match_df[(match_df["Date"] == row["Date"]) & (match_df["Team"] == row["Team"])]
                unique_home = match_subset["Home"].unique()
                unique_away = match_subset["Away"].unique()

                home_list.append("Multiple" if len(unique_home) > 1 else (unique_home[0] if len(unique_home) == 1 else "Unknown"))
                away_list.append("Multiple" if len(unique_away) > 1 else (unique_away[0] if len(unique_away) == 1 else "Unknown"))

            setter_df["Home"] = home_list
            setter_df["Away"] = away_list

        # Identify opponent per date based on Team grouping
        opponents = []
        for date, group in setter_df.groupby("Date"):
            teams = group["Team"].unique()
            for idx, row in group.iterrows():
                if row["Team"] == "Crandall":
                    if len(teams) == 2:
                        opponent = [t for t in teams if t != "Crandall"][0]
                    elif len(teams) > 2:
                        opponent = "Multiple"
                    else:
                        opponent = "Unknown"
                else:
                    opponent = "Crandall"
                opponents.append(opponent)

        setter_df["Opponent"] = opponents

        # Filters
        st.markdown("### ğŸ” Filter Setter Distribution Data")
        f1, f2, f3, f4 = st.columns(4)
        teams = sorted(setter_df["Team"].dropna().unique())
        opponents = sorted(setter_df["Opponent"].dropna().unique())
        tendencies = sorted(setter_df["Setter Tendency"].dropna().unique()) if "Setter Tendency" in setter_df.columns else []
        positions = sorted(setter_df["Position"].dropna().unique()) if "Position" in setter_df.columns else []

        f_team = f1.multiselect("Team", options=teams)
        f_oppo = f2.multiselect("Opponent", options=opponents)
        f_tend = f3.multiselect("Setter Tendency", options=tendencies)
        f_pos  = f4.multiselect("Position", options=positions)

        filtered_setter_df = setter_df.copy()
        if f_team:
            filtered_setter_df = filtered_setter_df[filtered_setter_df["Team"].isin(f_team)]
        if f_oppo:
            filtered_setter_df = filtered_setter_df[filtered_setter_df["Opponent"].isin(f_oppo)]
        if f_tend and "Setter Tendency" in filtered_setter_df.columns:
            filtered_setter_df = filtered_setter_df[filtered_setter_df["Setter Tendency"].isin(f_tend)]
        if f_pos and "Position" in filtered_setter_df.columns:
            filtered_setter_df = filtered_setter_df[filtered_setter_df["Position"].isin(f_pos)]

        st.success(f"âœ… Showing {filtered_setter_df.shape[0]} filtered rows from Setter Distribution Data")
        st.dataframe(filtered_setter_df)

        col1, col2 = st.columns([3, 1])
        with col1:
            st.download_button(
                "ğŸ’¾ Download Setter Distribution CSV",
                data=filtered_setter_df.to_csv(index=False).encode("utf-8"),
                file_name="setter_distribution_data.csv",
                mime="text/csv"
            )
        with col2:
            st.caption("ğŸ“Œ Direct from scouting reports and analytics exports")
    except Exception as e:
        st.error(f"âŒ Failed to load Setter Distribution Data: {e}")
else:
    st.warning("âš ï¸ Setter Distribution file not found at `data/Setter Distribution Data.csv`")

# -------------------------------
# Footer
# -------------------------------
st.markdown("---")
st.caption("Developed by Astute Innovations â€” Streamlit analytics platform â€¢ Crandall Chargers Volleyball Â© 2025")
